{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nishimura.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalgo-intern/kyushu/blob/main/trial_tanabe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aBD51zYeFmR"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFawUzKlhfrs"
      },
      "source": [
        "#1 ライブラリのインポート等\n",
        "\n",
        "import keras\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#from keras.utils import plot_model #これはKerasのバージョンなどにより使えないのでコメントアウト\n",
        "from keras.utils import np_utils #keras.utils.to_categoricalでエラーが出るので追加\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioL97Tx55Nmk"
      },
      "source": [
        "#2 各種設定 \n",
        "\n",
        "train_data_path = 'img' # ここを変更。Colaboratoryにアップロードしたzipファイルを解凍後の、データセットのフォルダ名を入力\n",
        "\n",
        "image_size = 80 # ここを変更。必要に応じて変更してください。「28」を指定した場合、縦28横28ピクセルの画像に変換します。\n",
        "\n",
        "color_setting = 3  #ここを変更。データセット画像のカラー：「1」はモノクロ・グレースケール。「3」はカラー。\n",
        "\n",
        "folder = ['high','mid','low'] # ここを変更。データセット画像のフォルダ名（クラス名）を半角英数で入力\n",
        "\n",
        "class_number = len(folder)\n",
        "print('今回のデータで分類するクラス数は「', str(class_number), '」です。')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIzdLPdT7HyZ"
      },
      "source": [
        "#3 データセットの読み込みとデータ形式の設定・正規化・分割 \n",
        "\n",
        "X_image = []  \n",
        "Y_label = [] \n",
        "for index, name in enumerate(folder):\n",
        "  read_data = train_data_path + '/' + name\n",
        "  files = glob.glob(read_data + '/*.png') #ここを変更。png形式のファイルを利用する場合のサンプルです。\n",
        "  print('--- 読み込んだデータセットは', read_data, 'です。')\n",
        "\n",
        "  for i, file in enumerate(files):  \n",
        "    if color_setting == 1:\n",
        "      img = load_img(file, color_mode = 'grayscale' ,target_size=(image_size, image_size))  \n",
        "    elif color_setting == 3:\n",
        "      img = load_img(file, color_mode = 'rgb' ,target_size=(image_size, image_size))\n",
        "    array = img_to_array(img)\n",
        "    X_image.append(array)\n",
        "    Y_label.append(index)\n",
        "\n",
        "X_image = np.array(X_image)\n",
        "Y_label = np.array(Y_label)\n",
        "\n",
        "X_image = X_image.astype('float32') / 255\n",
        "#Y_label = keras.utils.to_categorical(Y_label, class_number) #Kerasのバージョンなどにより使えないのでコメントアウト\n",
        "Y_label = np_utils.to_categorical(Y_label, class_number) #上記のコードのかわり\n",
        "\n",
        "train_images, valid_images, train_labels, valid_labels = train_test_split(X_image, Y_label, test_size=0.10)\n",
        "x_train = train_images\n",
        "y_train = train_labels\n",
        "x_test = valid_images\n",
        "y_test = valid_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqkFYulI7Ng1"
      },
      "source": [
        "#4 機械学習（人工知能）モデルの作成 – 畳み込みニューラルネットワーク（CNN）・学習の実行等\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding='same',\n",
        "          input_shape=(image_size, image_size, color_setting), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))               \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))                \n",
        "model.add(Dropout(0.5))                                   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))                                 \n",
        "model.add(Dense(class_number, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "#plot_model(model, to_file='model.png') #ここはKerasのバージョンなどにより使えないのでコメントアウト\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# ここを変更。必要に応じて「batch_size=」「epochs=」の数字を変更してみてください。\n",
        "history = model.fit(x_train,y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid()\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid()\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "open('cnn_model.json','w').write(model.to_json())\n",
        "model.save_weights('cnn_weights.h5') \n",
        "#model.save('cnn_model_weight.h5') #モデル構造と重みを1つにまとめることもできます\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Loss:', score[0], '（損失関数値 - 0に近いほど正解に近い）') \n",
        "print('Accuracy:', score[1] * 100, '%', '（精度 - 100% に近いほど正解に近い）') \n",
        "print('Computation time（計算時間）:{0:.3f} sec（秒）'.format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vf3SYl37ODs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}